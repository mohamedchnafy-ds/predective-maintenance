{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uytjxX5Lbpii"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from pathlib import Path\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('/content/drive/MyDrive/GDM5 project/data/combined_data.parquet')"
      ],
      "metadata": {
        "id": "0fusZD7Ob0N3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "zQv2HXok6ssa",
        "outputId": "7dd0e189-1410-4794-ee04-b21d7d5d3a7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-00cf07b74dcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many values  in colunm asset_id ?\n",
        "df['status_type_id'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "wgyVM4bYb6Wp",
        "outputId": "2cc92d94-82b1-4807-834d-3424198e3897"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status_type_id\n",
              "0    898672\n",
              "5    260387\n",
              "3     23689\n",
              "4     13999\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status_type_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>898672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>260387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#je veux créer une variable STATUS_ID qui vaut \"normal\" si la valeur de status_type_id vaut 0 ou 2 et \"not normal\" sinon\n",
        "df['status_id'] = np.where(df['status_type_id'].isin([0, 2]), 'normal', 'not normal')"
      ],
      "metadata": {
        "id": "vnrwEEiS60by"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['status_id'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "cf_I8Jhb7KQz",
        "outputId": "9913af73-ce89-4605-bfca-765cde4fd149"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status_id\n",
              "normal        898672\n",
              "not normal    298075\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>normal</th>\n",
              "      <td>898672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not normal</th>\n",
              "      <td>298075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sensor_columns = [col for col in df.columns if any(x in col for x in\n",
        "                        ['sensor', 'wind_speed', 'power'])]\n",
        "len(sensor_columns)"
      ],
      "metadata": {
        "id": "H9-IzRyRdkd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71355715-b3cb-46dd-d4ad-766c307308ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuration de l'affichage\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"deep\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 12"
      ],
      "metadata": {
        "id": "N08ooIkEccX7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim=16):\n",
        "        \"\"\"\n",
        "        Architecture de l'autoencoder pour la détection d'anomalies\n",
        "\n",
        "        Args:\n",
        "            input_dim: Dimension des données d'entrée (nombre de capteurs)\n",
        "            encoding_dim: Dimension de la couche latente (compressée)\n",
        "        \"\"\"\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 44),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(44, 25),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(25, 4),  # Couche latente\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        # Décodeur - reconstruit les données à partir de la représentation compressée\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(4, 25),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(25, 44),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(44, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Propagation avant: encode puis décode les données\"\"\"\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "tbTBTGkScX1e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class REPredictor(nn.Module):\n",
        "    \"\"\"Neural Network for predicting Reconstruction Error.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=30):\n",
        "        super(REPredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, 1)  # Outputting a single RE value\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FXQU_0a-8JVd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WindTurbineAnomalyDetector:\n",
        "    def __init__(self, encoding_dim=16, hidden_dim=30,gamma=0.344):\n",
        "        \"\"\"\n",
        "        Détecteur d'anomalies pour les données d'éoliennes\n",
        "\n",
        "        Args:\n",
        "            encoding_dim: Dimension de la couche latente de l'autoencoder\n",
        "        \"\"\"\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.scaler = StandardScaler()  # Pour normaliser les données\n",
        "        self.model = None\n",
        "        self.hidden_dim = hidden_dim # Assigned hidden_dim to an attribute\n",
        "        self.re_predictor = None\n",
        "        self.gamma = gamma\n",
        "        self.threshold = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Utilisation de: {self.device}\")\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        \"\"\"\n",
        "        Prétraitement des données: sélection et normalisation des capteurs\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame contenant les données des capteurs\n",
        "\n",
        "        Returns:\n",
        "            X_scaled: Données normalisées\n",
        "            sensor_columns: Noms des colonnes sélectionnées\n",
        "        \"\"\"\n",
        "        # Sélection des colonnes pertinentes (capteurs uniquement)\n",
        "        sensor_columns = [col for col in df.columns if any(x in col for x in\n",
        "                        ['sensor', 'wind_speed', 'power'])]\n",
        "\n",
        "        print(f\"Nombre de capteurs sélectionnés: {len(sensor_columns)}\")\n",
        "\n",
        "        # Vérification et nettoyage des données\n",
        "        X = df[sensor_columns].copy()\n",
        "\n",
        "        # Remplacer les valeurs infinies par NaN\n",
        "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "        # Vérifier s'il y a des valeurs NaN et les remplacer par la moyenne de la colonne\n",
        "        if X.isna().any().any():\n",
        "            print(f\"Attention: {X.isna().sum().sum()} valeurs NaN détectées et remplacées\")\n",
        "            X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "        # Normalisation des caractéristiques\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        return X_scaled, sensor_columns\n",
        "    def train_re_predictor(self, normal_data, epochs=300, batch_size=64, learning_rate=0.001, patience=10, checkpoint_dir='checkpoints_NN'):\n",
        "        \"\"\"Trains the RE Predictor NN with early stopping.\"\"\"\n",
        "\n",
        "        X, _ = self.preprocess_data(normal_data)  # Preprocess normal data\n",
        "        if self.re_predictor is None:\n",
        "            self.re_predictor = REPredictor(input_dim=X.shape[1], hidden_dim=self.hidden_dim).to(self.device)\n",
        "\n",
        "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
        "        dataset = TensorDataset(X_tensor, X_tensor)  # Input = Output (for RE)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        criterion = nn.MSELoss()  # Loss function for regression\n",
        "        optimizer = optim.Adam(self.re_predictor.parameters(), lr=learning_rate)\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        epochs_without_improvement = 0\n",
        "        # Create checkpoint directory if it doesn't exist\n",
        "        Path(checkpoint_dir).mkdir(exist_ok=True)\n",
        "        start_epoch = 0\n",
        "        # Load the latest checkpoint if it exists\n",
        "        checkpoints = list(Path(checkpoint_dir).glob('epoch_NN_*.pth'))\n",
        "        if checkpoints:\n",
        "            latest_checkpoint = max(checkpoints, key=lambda p: int(p.stem.split('_')[2]))\n",
        "            checkpoint = torch.load(latest_checkpoint)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            self.re_predictor.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            print(f\"RE Predictor: Reprise de l'entraînement à partir de l'epoch {start_epoch}\")\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            self.re_predictor.train()  # Set the model to training mode\n",
        "\n",
        "            for data, _ in dataloader:\n",
        "                # Forward pass\n",
        "                outputs = self.re_predictor(data)\n",
        "                loss = criterion(outputs, data)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            print(f'RE Predictor Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.6f}')\n",
        "\n",
        "            # Early stopping check\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                epochs_without_improvement = 0\n",
        "            else:\n",
        "                epochs_without_improvement += 1\n",
        "                if epochs_without_improvement >= patience:\n",
        "                    print(f'Early stopping triggered after {epoch + 1} epochs.')\n",
        "                    break\n",
        "                    # Save checkpoint after each epoch\n",
        "            checkpoint_path = Path(checkpoint_dir) / f'epoch_NN_{epoch + 1}.pth'\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': self.re_predictor.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, checkpoint_path)\n",
        "\n",
        "    def train(self, df, epochs=50, batch_size=64, learning_rate=0.0001,checkpoint_dir='checkpoints'):\n",
        "        \"\"\"\n",
        "        Entraînement de l'autoencoder\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame contenant les données d'entraînement\n",
        "            epochs: Nombre d'époques d'entraînement\n",
        "            batch_size: Taille des lots pour l'entraînement\n",
        "            learning_rate: Taux d'apprentissage\n",
        "\n",
        "        Returns:\n",
        "            losses: Liste des pertes d'entraînement\n",
        "        \"\"\"\n",
        "        # Prétraitement des données\n",
        "        X, sensor_columns = self.preprocess_data(df)\n",
        "\n",
        "        # Conversion en tenseurs PyTorch\n",
        "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
        "        dataset = TensorDataset(X_tensor, X_tensor)  # Les entrées = sorties attendues\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Construction du modèle\n",
        "        if self.model is None:\n",
        "            self.model = Autoencoder(X.shape[1], self.encoding_dim).to(self.device)\n",
        "            print(f\"Modèle créé avec {X.shape[1]} entrées et dimension latente de {self.encoding_dim}\")\n",
        "\n",
        "        # Fonction de perte et optimiseur\n",
        "        criterion = nn.MSELoss()  # Erreur quadratique moyenne\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)  # Ajout de régularisation L2\n",
        "\n",
        "        # Créer le répertoire de checkpoints s'il n'existe pas\n",
        "        Path(checkpoint_dir).mkdir(exist_ok=True)\n",
        "\n",
        "        start_epoch = 0\n",
        "        # Charger le dernier checkpoint s'il existe\n",
        "        checkpoints = list(Path(checkpoint_dir).glob('epoch_*.pth'))\n",
        "        if checkpoints:\n",
        "            latest_checkpoint = max(checkpoints, key=lambda p: int(p.stem.split('_')[1]))\n",
        "            checkpoint = torch.load(latest_checkpoint)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            print(f\"Reprise de l'entraînement à partir de l'epoch {start_epoch}\")\n",
        "\n",
        "        # Boucle d'entraînement\n",
        "        losses = []\n",
        "        self.model.train()  # Mode entraînement\n",
        "        # Boucle d'entraînement\n",
        "        losses = []\n",
        "        self.model.train()  # Mode entraînement\n",
        "\n",
        "        print(\"Début de l'entraînement...\")\n",
        "        for epoch in range(start_epoch,epochs):\n",
        "\n",
        "            epoch_loss = 0\n",
        "            for data, _ in dataloader:\n",
        "                # Propagation avant\n",
        "                outputs = self.model(data)\n",
        "                loss = criterion(outputs, data)\n",
        "\n",
        "                # Vérification de la perte\n",
        "                if torch.isnan(loss):\n",
        "                    print(f\"Alerte: Perte NaN détectée à l'époque {epoch+1}. Arrêt de l'entraînement.\")\n",
        "                    return losses\n",
        "\n",
        "                # Rétropropagation\n",
        "                optimizer.zero_grad()  # Réinitialisation des gradients\n",
        "                loss.backward()        # Calcul des gradients\n",
        "\n",
        "                # Clip des gradients pour éviter l'explosion\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()       # Mise à jour des poids\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            # Calcul de la perte moyenne pour cette époque\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            losses.append(avg_loss)\n",
        "\n",
        "            print(f'Époque [{epoch+1}/{epochs}], Perte: {avg_loss:.6f}')\n",
        "            # Enregistrer le checkpoint\n",
        "            checkpoint_path = Path(checkpoint_dir) / f'epoch_{epoch + 1}.pth'\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, checkpoint_path)\n",
        "\n",
        "        print(\"Entraînement terminé!\")\n",
        "\n",
        "        # Calcul du seuil d'erreur de reconstruction\n",
        "        self.model.eval()  # Mode évaluation\n",
        "        with torch.no_grad():\n",
        "            reconstructions = self.model(X_tensor).cpu().numpy()\n",
        "\n",
        "        # Calcul de l'erreur quadratique moyenne pour chaque exemple\n",
        "        mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
        "\n",
        "        # Définition du seuil comme le 95ème percentile des erreurs\n",
        "        self.threshold = np.percentile(mse, 95)\n",
        "        print(f\"Seuil d'anomalie calculé: {self.threshold:.6f}\")\n",
        "\n",
        "        return losses\n",
        "\n",
        "    def detect_anomalies(self, df):\n",
        "        \"\"\"\n",
        "        Détection des anomalies dans les données\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame contenant les données à analyser\n",
        "\n",
        "        Returns:\n",
        "            results: DataFrame avec les erreurs de reconstruction et les anomalies\n",
        "        \"\"\"\n",
        "        # Prétraitement des données\n",
        "        X, _ = self.preprocess_data(df)\n",
        "\n",
        "        # Conversion en tenseurs PyTorch + noise\n",
        "        noise_factor = 0.06\n",
        "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
        "        X_tensor = X_tensor + noise_factor * torch.randn(X_tensor.shape).to(self.device)\n",
        "        # Obtention des reconstructions\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            reconstructions = self.model(X_tensor).cpu().numpy()\n",
        "\n",
        "        # Calcul de l'erreur MSE\n",
        "        expected_re = self.re_predictor(X_tensor).detach().cpu().numpy().flatten()\n",
        "        threshold = expected_re + gamma\n",
        "        mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
        "\n",
        "        # Détection des anomalies (erreur > seuil)\n",
        "        anomalies = mse > threshold\n",
        "\n",
        "        # Création d'un DataFrame avec les résultats\n",
        "        results = pd.DataFrame({\n",
        "            'reconstruction_error': mse,\n",
        "            'anomaly': anomalies\n",
        "        }, index=df.index)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_history(self, losses):\n",
        "        \"\"\"Visualisation de l'historique d'entraînement\"\"\"\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.plot(losses)\n",
        "        plt.title('Évolution de la perte pendant l\\'entraînement')\n",
        "        plt.xlabel('Époque')\n",
        "        plt.ylabel('Perte (MSE)')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_anomalies(self, df, results):\n",
        "        \"\"\"Visualisation des anomalies détectées\"\"\"\n",
        "        plt.figure(figsize=(15, 7))\n",
        "\n",
        "        # Tri par timestamp\n",
        "        df_sorted = df.sort_values('time_stamp')\n",
        "        results_sorted = results.loc[df_sorted.index]\n",
        "\n",
        "        # Tracé de l'erreur de reconstruction\n",
        "        plt.scatter(df_sorted['time_stamp'], results_sorted['reconstruction_error'],\n",
        "                   c=results_sorted['anomaly'], cmap='coolwarm', alpha=0.7)\n",
        "\n",
        "        plt.axhline(y=self.threshold, color='r', linestyle='--', label=f'Seuil ({self.threshold:.4f})')\n",
        "        plt.title('Détection d\\'anomalies dans les données d\\'éoliennes')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Erreur de reconstruction')\n",
        "        plt.colorbar(label='Anomalie')\n",
        "        plt.legend()\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Distribution des erreurs de reconstruction\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.histplot(results['reconstruction_error'], bins=50, kde=True)\n",
        "        plt.axvline(x=self.threshold, color='r', linestyle='--', label=f'Seuil ({self.threshold:.4f})')\n",
        "        plt.title('Distribution des erreurs de reconstruction')\n",
        "        plt.xlabel('Erreur de reconstruction')\n",
        "        plt.ylabel('Fréquence')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.boxplot(x=results['anomaly'], y=results['reconstruction_error'])\n",
        "        plt.title('Erreurs de reconstruction par classe')\n",
        "        plt.xlabel('Anomalie')\n",
        "        plt.ylabel('Erreur de reconstruction')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "1zF4oUkecuBJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sensor_contribution(detector, test_data, anomaly_results):\n",
        "    \"\"\"Analyse la contribution de chaque capteur aux anomalies détectées\"\"\"\n",
        "    # Prétraitement des données\n",
        "    X, sensor_columns = detector.preprocess_data(test_data)\n",
        "\n",
        "    # Conversion en tenseurs PyTorch\n",
        "    X_tensor = torch.FloatTensor(X).to(detector.device)\n",
        "\n",
        "    # Obtention des reconstructions\n",
        "    detector.model.eval()\n",
        "    with torch.no_grad():\n",
        "        reconstructions = detector.model(X_tensor).cpu().numpy()\n",
        "\n",
        "    # Calcul de l'erreur par capteur\n",
        "    sensor_errors = np.power(X - reconstructions, 2)\n",
        "\n",
        "    # Création d'un DataFrame avec les erreurs par capteur\n",
        "    sensor_error_df = pd.DataFrame(sensor_errors, columns=sensor_columns)\n",
        "\n",
        "    # Ajout de l'information d'anomalie\n",
        "    sensor_error_df['anomaly'] = anomaly_results['anomaly'].values\n",
        "\n",
        "    # Calcul de l'erreur moyenne par capteur pour les anomalies vs non-anomalies\n",
        "    anomaly_errors = sensor_error_df[sensor_error_df['anomaly']].mean()\n",
        "    normal_errors = sensor_error_df[~sensor_error_df['anomaly']].mean()\n",
        "\n",
        "    # Calcul du ratio d'erreur (anomalie / normal)\n",
        "    error_ratio = anomaly_errors / normal_errors\n",
        "    error_ratio = error_ratio.drop('anomaly')\n",
        "\n",
        "    # Tri des capteurs par ratio d'erreur\n",
        "    top_sensors = error_ratio.sort_values(ascending=False)\n",
        "\n",
        "    return top_sensors, sensor_error_df\n"
      ],
      "metadata": {
        "id": "rEvnrIbOc0BK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_analysis():\n",
        "    # Chargement des données\n",
        "    #data_path = Path(r'/content/drive/MyDrive/GDM5 project/combined_data.parquet')\n",
        "    #df = pd.read_parquet(data_path)\n",
        "\n",
        "    # Conversion du timestamp en format datetime\n",
        "    df['time_stamp'] = pd.to_datetime(df['time_stamp'], format='mixed')\n",
        "\n",
        "    # Séparation des données d'entraînement et de test\n",
        "    train_data = df[(df['train_test'] == 'train') & (df['status_id'] == 'normal')] # Nouvelle ligne\n",
        "    test_data = df[df['train_test'] == 'prediction']\n",
        "\n",
        "    print(f\"\\nDonnées d'entraînement: {len(train_data)} lignes\")\n",
        "    print(f\"Données de test: {len(test_data)} lignes\")\n",
        "\n",
        "    # Création et entraînement du détecteur\n",
        "    detector = WindTurbineAnomalyDetector(encoding_dim=16)\n",
        "    losses = detector.train(train_data, epochs=20, batch_size=64, learning_rate=0.0018, checkpoint_dir='analysis_checkpoints')\n",
        "    detector.train_re_predictor(normal_data=train_data, epochs=300, batch_size=64, learning_rate=0.001, checkpoint_dir='analysis_checkpoints')\n",
        "    # Visualisation de l'entraînement\n",
        "    detector.plot_history(losses)\n",
        "\n",
        "    # Détection des anomalies\n",
        "    print(\"Détection des anomalies sur les données de test...\")\n",
        "    anomaly_results = detector.detect_anomalies(test_data)\n",
        "\n",
        "    # Statistiques des anomalies\n",
        "    anomaly_count = anomaly_results['anomaly'].sum()\n",
        "    print(f\"Nombre d'anomalies détectées: {anomaly_count}\")\n",
        "    print(f\"Pourcentage d'anomalies: {(anomaly_count / len(test_data)) * 100:.2f}%\")\n",
        "\n",
        "    # Visualisation des anomalies\n",
        "    detector.plot_anomalies(test_data, anomaly_results)\n",
        "\n",
        "    # Analyse des capteurs les plus influents\n",
        "    top_sensors, sensor_error_df = analyze_sensor_contribution(detector, test_data, anomaly_results)\n",
        "\n",
        "    # Visualisation des capteurs les plus influents\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    top_sensors.head(15).plot(kind='bar')\n",
        "    plt.title('Top 15 des capteurs contribuant le plus aux anomalies')\n",
        "    plt.xlabel('Capteur')\n",
        "    plt.ylabel('Ratio d\\'erreur (Anomalie/Normal)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Sauvegarde du modèle\n",
        "    model_path = Path(r'c:\\Users\\moham\\Desktop\\GDM5 project\\models')\n",
        "    model_path.mkdir(exist_ok=True)\n",
        "    torch.save(detector.model.state_dict(), model_path / 'autoencoder_model.pth')\n",
        "    joblib.dump(detector.scaler, model_path / 'scaler.pkl')\n",
        "    joblib.dump(detector.threshold, model_path / 'threshold.pkl')\n",
        "\n",
        "    return detector, anomaly_results, top_sensors\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Exécuter l'analyse complète\n",
        "    detector, anomaly_results, top_sensors = run_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nY5N6MP9c4wO",
        "outputId": "d8a9cc3c-0721-4b58-be06-d898511943fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Données d'entraînement: 859574 lignes\n",
            "Données de test: 50593 lignes\n",
            "Utilisation de: cuda\n",
            "Nombre de capteurs sélectionnés: 81\n",
            "Attention: 10 valeurs NaN détectées et remplacées\n",
            "Modèle créé avec 81 entrées et dimension latente de 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-94093113edc5>:154: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(latest_checkpoint)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reprise de l'entraînement à partir de l'epoch 20\n",
            "Début de l'entraînement...\n",
            "Entraînement terminé!\n",
            "Seuil d'anomalie calculé: 2.007583\n",
            "Nombre de capteurs sélectionnés: 81\n",
            "Attention: 10 valeurs NaN détectées et remplacées\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([64, 81])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([54, 81])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RE Predictor Epoch [1/300], Loss: 0.772981\n",
            "RE Predictor Epoch [2/300], Loss: 0.773033\n",
            "RE Predictor Epoch [3/300], Loss: 0.773096\n",
            "RE Predictor Epoch [4/300], Loss: 0.773246\n",
            "RE Predictor Epoch [5/300], Loss: 0.774543\n",
            "RE Predictor Epoch [6/300], Loss: 0.798416\n",
            "RE Predictor Epoch [7/300], Loss: 0.802432\n",
            "RE Predictor Epoch [8/300], Loss: 0.859258\n",
            "RE Predictor Epoch [9/300], Loss: 0.778915\n",
            "RE Predictor Epoch [10/300], Loss: 0.775473\n",
            "RE Predictor Epoch [11/300], Loss: 0.829625\n",
            "Early stopping triggered after 11 epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Détection des anomalies sur les données de test...\n",
            "Nombre de capteurs sélectionnés: 81\n",
            "Attention: 8 valeurs NaN détectées et remplacées\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gamma' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-02b1abf45fb4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Exécuter l'analyse complète\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_sensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-02b1abf45fb4>\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Détection des anomalies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Détection des anomalies sur les données de test...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0manomaly_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Statistiques des anomalies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-94093113edc5>\u001b[0m in \u001b[0;36mdetect_anomalies\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Calcul de l'erreur MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mexpected_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_re\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gamma' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "checkpoint_dir = 'analysis_checkpoints'  # Remplacez par le répertoire approprié\n",
        "\n",
        "for filename in os.listdir(checkpoint_dir):\n",
        "    if filename.startswith('epoch_') and filename.endswith('.pth'):\n",
        "        file_path = os.path.join(checkpoint_dir, filename)\n",
        "        os.remove(file_path)\n",
        "\n",
        "# Ou, pour supprimer tout le contenu du répertoire :\n",
        "# shutil.rmtree(checkpoint_dir)  # Attention, cela supprimera tout dans le répertoire !"
      ],
      "metadata": {
        "id": "c1kSzm2i2kGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#how to know number of category in column\n",
        "\n",
        "anomaly_results"
      ],
      "metadata": {
        "id": "so7nAYOEuwCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Coverage:\n",
        "    def __init__(self, beta=0.5):\n",
        "        \"\"\"\n",
        "        Initializes the Coverage class.\n",
        "\n",
        "        Args:\n",
        "            beta: Beta value for the Fβ-score (default: 0.5).\n",
        "        \"\"\"\n",
        "        self.beta = beta\n",
        "\n",
        "    def filter_prediction_time_frame(self, df):\n",
        "        \"\"\"\n",
        "        Filters the prediction time frame to include only data points with a normal status ID.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing the data with a 'status_id' column.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame containing only data points with a normal status ID.\n",
        "        \"\"\"\n",
        "        filtered_df = df[df['status_id'] == 'normal']\n",
        "        return filtered_df\n",
        "\n",
        "    def calculate_fbeta_score(self, ground_truth, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the Fβ-score for the given ground truth and predictions.\n",
        "\n",
        "        Args:\n",
        "            ground_truth: Ground truth labels (0 or 1).\n",
        "            predictions: Predicted labels (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            The Fβ-score.\n",
        "        \"\"\"\n",
        "        tp = np.sum((ground_truth == 1) & (predictions == 1))\n",
        "        fn = np.sum((ground_truth == 1) & (predictions == 0))\n",
        "        fp = np.sum((ground_truth == 0) & (predictions == 1))\n",
        "\n",
        "        fbeta = (1 + self.beta**2) * tp / ((1 + self.beta**2) * tp + self.beta**2 * fn + fp)\n",
        "        return fbeta\n",
        "\n",
        "    def calculate_coverage_score(self, df, anomaly_results):\n",
        "        \"\"\"\n",
        "        Calculates the Coverage score for the given data and anomaly results.\n",
        "\n",
        "        Args:\n",
        "            df: Original DataFrame containing the data.\n",
        "            anomaly_results: DataFrame containing the anomaly predictions.\n",
        "\n",
        "        Returns:\n",
        "            The Coverage score.\n",
        "        \"\"\"\n",
        "        filtered_df = self.filter_prediction_time_frame(df)\n",
        "\n",
        "        # Extract ground truth and predictions for the filtered time frame\n",
        "        ground_truth = filtered_df['status_id'].map({'normal': 0, 'not normal': 1}).astype(int)\n",
        "        predictions = anomaly_results['anomaly'].astype(int)\n",
        "\n",
        "        # Calculate the Coverage score (Fβ-score)\n",
        "        coverage_score = self.calculate_fbeta_score(ground_truth, predictions)\n",
        "        return coverage_score"
      ],
      "metadata": {
        "id": "QCfV2aih8Ar_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coverage_calculator = Coverage(beta=0.5)  # Create an instance of the class\n",
        "\n",
        "# Calculate the Coverage score\n",
        "coverage_score = coverage_calculator.calculate_coverage_score(df, anomaly_results)\n",
        "\n",
        "print(f\"Coverage Score: {coverage_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9W5jWL8ivMQ",
        "outputId": "1010d353-876e-4a03-9e83-76cb048d9693"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Accuracy:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes the Accuracy class.\"\"\"\n",
        "        pass  # No specific initialization needed for this score\n",
        "\n",
        "    def filter_prediction_time_frame(self, df):\n",
        "        \"\"\"\n",
        "        Filters the prediction time frame to include only data points with a normal status ID.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing the data with a 'status_id' column.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame containing only data points with a normal status ID.\n",
        "        \"\"\"\n",
        "        filtered_df = df[df['status_id'] == 'normal']\n",
        "        return filtered_df\n",
        "\n",
        "    def calculate_acc_score(self, ground_truth, predictions):\n",
        "        \"\"\"\n",
        "        Calculates the Acc-score for the given ground truth and predictions.\n",
        "\n",
        "        Args:\n",
        "            ground_truth: Ground truth labels (0 or 1).\n",
        "            predictions: Predicted labels (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            The Acc-score.\n",
        "        \"\"\"\n",
        "        tn = np.sum((ground_truth == 0) & (predictions == 0))\n",
        "        fp = np.sum((ground_truth == 0) & (predictions == 1))\n",
        "\n",
        "        acc_score = tn / (fp + tn)\n",
        "        return acc_score\n",
        "\n",
        "    def calculate_accuracy_score(self, df, anomaly_results):\n",
        "        \"\"\"\n",
        "        Calculates the Accuracy score for the given data and anomaly results.\n",
        "\n",
        "        Args:\n",
        "            df: Original DataFrame containing the data.\n",
        "            anomaly_results: DataFrame containing the anomaly predictions.\n",
        "\n",
        "        Returns:\n",
        "            The Accuracy score.\n",
        "        \"\"\"\n",
        "        filtered_df = self.filter_prediction_time_frame(df)\n",
        "\n",
        "        # Extract ground truth and predictions for the filtered time frame\n",
        "        ground_truth = filtered_df['anomaly'].astype(int)  # Convert anomaly column to 0/1\n",
        "        predictions = anomaly_results.loc[filtered_df.index, 'anomaly'].astype(int)\n",
        "\n",
        "        # Calculate the Accuracy score (Acc-score)\n",
        "        accuracy_score = self.calculate_acc_score(ground_truth, predictions)\n",
        "        return accuracy_score"
      ],
      "metadata": {
        "id": "r_dGvKVejiOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_calculator = Accuracy()  # Create an instance of the class\n",
        "\n",
        "# Calculate the Accuracy score\n",
        "accuracy_score = accuracy_calculator.calculate_accuracy_score(df, anomaly_results)\n",
        "\n",
        "print(f\"Accuracy Score: {accuracy_score}\")"
      ],
      "metadata": {
        "id": "3aJSL9Kmjmnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class ReliabilityScoreCalculator:\n",
        "    def __init__(self, beta=0.5, threshold=72):\n",
        "        \"\"\"\n",
        "        Initializes the ReliabilityScoreCalculator class.\n",
        "\n",
        "        Args:\n",
        "            beta: Beta value for Fβ-score (default: 0.5).\n",
        "            threshold: Criticality threshold for event classification (default: 72).\n",
        "        \"\"\"\n",
        "        self.beta = beta\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def _calculate_criticality(self, status_info, predictions):\n",
        "        \"\"\"Calculates the criticality measure based on Algorithm 1.\"\"\"\n",
        "        crit = [0]\n",
        "        for i in range(1, len(status_info)):\n",
        "            if status_info[i] == 0:  # Abnormal status\n",
        "                if predictions[i] == 1:  # Anomaly detected\n",
        "                    crit.append(crit[-1] + 1)\n",
        "                else:\n",
        "                    crit.append(max(crit[-1] - 1, 0))\n",
        "            else:  # Normal status\n",
        "                crit.append(crit[-1])\n",
        "        return crit\n",
        "\n",
        "    def _classify_events(self, criticality):\n",
        "        \"\"\"Classifies predictions into anomaly events or normal behavior.\"\"\"\n",
        "        max_criticality = max(criticality)\n",
        "        event_classifications = [1 if max_criticality > self.threshold else 0] * len(criticality)\n",
        "        return event_classifications\n",
        "\n",
        "    def _calculate_fbeta_score(self, ground_truth, predictions):\n",
        "        \"\"\"Calculates the Fβ-score.\"\"\"\n",
        "        tp = np.sum((ground_truth == 1) & (predictions == 1))\n",
        "        fn = np.sum((ground_truth == 1) & (predictions == 0))\n",
        "        fp = np.sum((ground_truth == 0) & (predictions == 1))\n",
        "        fbeta = (1 + self.beta**2) * tp / ((1 + self.beta**2) * tp + self.beta**2 * fn + fp)\n",
        "        return fbeta\n",
        "\n",
        "    def calculate_reliability_score(self, df, anomaly_results):\n",
        "        \"\"\"\n",
        "        Calculates the Reliability score using the event-based Fβ-score.\n",
        "\n",
        "        Args:\n",
        "            df: Original DataFrame with 'status_id' and 'anomaly' columns.\n",
        "            anomaly_results: DataFrame with anomaly predictions.\n",
        "\n",
        "        Returns:\n",
        "            The Reliability score.\n",
        "        \"\"\"\n",
        "        status_info = df['status_id'].map({'normal': 1, 'not normal': 0}).values\n",
        "        predictions = anomaly_results['anomaly'].astype(int).values\n",
        "        criticality = self._calculate_criticality(status_info, predictions)\n",
        "        event_classifications = self._classify_events(criticality)\n",
        "        ground_truth_events = df['anomaly'].astype(int).values\n",
        "        return self._calculate_fbeta_score(ground_truth_events, event_classifications)"
      ],
      "metadata": {
        "id": "36wdlMC7kzt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your original DataFrame and 'anomaly_results' contains your predictions\n",
        "reliability_calculator = ReliabilityScoreCalculator(beta=0.5, threshold=72)\n",
        "\n",
        "# Calculate the Reliability score\n",
        "reliability_score = reliability_calculator.calculate_reliability_score(df, anomaly_results)\n",
        "\n",
        "print(f\"Reliability Score: {reliability_score}\")"
      ],
      "metadata": {
        "id": "6OcmmD_skzyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class EarlinessScoreCalculator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes the EarlinessScoreCalculator class.\"\"\"\n",
        "        pass  # No specific initialization needed for this score\n",
        "\n",
        "    def _calculate_weighted_score(self, anomaly_event_timestamps, predictions):\n",
        "        \"\"\"Calculates the Weighted Score (WS) for an anomaly event.\"\"\"\n",
        "        num_timestamps = len(anomaly_event_timestamps)\n",
        "        weights = np.ones(num_timestamps)  # Initialize weights to 1\n",
        "\n",
        "        # Apply weighting function (linear decrease in second half)\n",
        "        midpoint = num_timestamps // 2\n",
        "        weights[midpoint:] = np.linspace(1, 0, num_timestamps - midpoint)\n",
        "\n",
        "        # Calculate weighted score\n",
        "        weighted_score = np.sum(weights * predictions) / np.sum(weights)\n",
        "        return weighted_score\n",
        "\n",
        "    def calculate_earliness_score(self, df, anomaly_results):\n",
        "        \"\"\"\n",
        "        Calculates the Earliness score for the given data and anomaly results.\n",
        "\n",
        "        Args:\n",
        "            df: Original DataFrame with 'anomaly' column.\n",
        "            anomaly_results: DataFrame with anomaly predictions.\n",
        "\n",
        "        Returns:\n",
        "            The Earliness score.\n",
        "        \"\"\"\n",
        "        # Filter for anomaly events\n",
        "        anomaly_events = df[df['anomaly'] == 1]\n",
        "\n",
        "        # Get timestamps and predictions for each anomaly event\n",
        "        event_timestamps = anomaly_events.index.tolist()\n",
        "        event_predictions = anomaly_results.loc[event_timestamps, 'anomaly'].astype(int).values\n",
        "\n",
        "        # Calculate weighted score for each event\n",
        "        weighted_scores = []\n",
        "        for i in range(len(event_timestamps)):\n",
        "            weighted_scores.append(self._calculate_weighted_score([event_timestamps[i]], [event_predictions[i]]))\n",
        "\n",
        "        # Calculate overall Earliness score (average of weighted scores)\n",
        "        earliness_score = np.mean(weighted_scores) if weighted_scores else 0  # Handle case with no anomaly events\n",
        "        return earliness_score"
      ],
      "metadata": {
        "id": "0JSQ0lIWk2Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your original DataFrame and 'anomaly_results' contains your predictions\n",
        "earliness_calculator = EarlinessScoreCalculator()\n",
        "\n",
        "# Calculate the Earliness score\n",
        "earliness_score = earliness_calculator.calculate_earliness_score(df, anomaly_results)\n",
        "\n",
        "print(f\"Earliness Score: {earliness_score}\")"
      ],
      "metadata": {
        "id": "Zvcjlhp3lSlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}