{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1EhVKvipNc-pe3tjnKyWJO2cMbbbY6QkB","authorship_tag":"ABX9TyPmAAElto0gQBNA5ttiIidp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uytjxX5Lbpii","executionInfo":{"status":"ok","timestamp":1741695869521,"user_tz":-60,"elapsed":12973,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from pathlib import Path\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","import joblib"]},{"cell_type":"code","source":["df = pd.read_parquet('/content/drive/MyDrive/GDM5 project/combined_data.parquet')"],"metadata":{"id":"0fusZD7Ob0N3","executionInfo":{"status":"ok","timestamp":1741695876741,"user_tz":-60,"elapsed":7206,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"id":"zQv2HXok6ssa","executionInfo":{"status":"ok","timestamp":1741695877318,"user_tz":-60,"elapsed":583,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}},"outputId":"e2a78815-80b7-4dd5-af2a-a22180480624"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        name_file           time_stamp  asset_id     id  train_test  \\\n","0           0.csv     03/08/2022 06:10         0      0       train   \n","1           0.csv     03/08/2022 06:20         0      1       train   \n","2           0.csv     03/08/2022 06:30         0      2       train   \n","3           0.csv     03/08/2022 06:40         0      3       train   \n","4           0.csv     03/08/2022 06:50         0      4       train   \n","...           ...                  ...       ...    ...         ...   \n","1196742    92.csv  2023-04-16 09:20:00        11  54062  prediction   \n","1196743    92.csv  2023-04-16 09:30:00        11  54063  prediction   \n","1196744    92.csv  2023-04-16 09:40:00        11  54064  prediction   \n","1196745    92.csv  2023-04-16 09:50:00        11  54065  prediction   \n","1196746    92.csv  2023-04-16 10:00:00        11  54066  prediction   \n","\n","         status_type_id  sensor_0_avg  sensor_1_avg  sensor_2_avg  \\\n","0                     0          22.0         302.9         129.4   \n","1                     0          22.0         307.1         133.6   \n","2                     0          22.0         340.6         167.1   \n","3                     0          22.0         124.4         -49.1   \n","4                     0          22.0          66.2        -107.3   \n","...                 ...           ...           ...           ...   \n","1196742               5          15.0         117.8           4.8   \n","1196743               5          16.0          69.7         -32.0   \n","1196744               5          16.0          69.8         -16.9   \n","1196745               5          16.0          63.5         -10.6   \n","1196746               5          16.0          91.9          17.8   \n","\n","         wind_speed_3_avg  ...  sensor_47  sensor_48  sensor_49  sensor_50  \\\n","0                     1.7  ...     -496.0        0.0        0.0    -1280.0   \n","1                     1.7  ...     -490.0        0.0        0.0    -1278.0   \n","2                     0.9  ...     -490.0        0.0        0.0    -1356.0   \n","3                     1.5  ...     -509.0        0.0        0.0    -1274.0   \n","4                     1.0  ...     -499.0        0.0        0.0    -1284.0   \n","...                   ...  ...        ...        ...        ...        ...   \n","1196742               2.7  ...     -328.0        0.0        0.0     -772.0   \n","1196743               2.3  ...     -231.0        0.0        0.0     -725.0   \n","1196744               2.8  ...     -492.0        0.0        0.0     -844.0   \n","1196745               2.4  ...     -228.0        0.0        0.0     -731.0   \n","1196746               3.1  ...     -544.0        0.0        0.0     -858.0   \n","\n","         sensor_51  sensor_52_avg  sensor_52_max  sensor_52_min  \\\n","0           -496.0            0.0            0.0            0.0   \n","1           -490.0            0.0            0.0            0.0   \n","2           -490.0            0.0            0.0            0.0   \n","3           -509.0            0.0            0.0            0.0   \n","4           -499.0            0.0            0.0            0.0   \n","...            ...            ...            ...            ...   \n","1196742     -328.0            1.4            2.7            0.0   \n","1196743     -231.0            0.3            2.1            0.0   \n","1196744     -492.0            1.9            2.1            1.6   \n","1196745     -228.0            0.4            1.8            0.0   \n","1196746     -544.0            1.9            2.2            0.0   \n","\n","         sensor_52_std  sensor_53_avg  \n","0                  0.0           26.0  \n","1                  0.0           25.0  \n","2                  0.0           25.0  \n","3                  0.0           26.0  \n","4                  0.0           26.0  \n","...                ...            ...  \n","1196742            1.1           18.0  \n","1196743            0.7           18.0  \n","1196744            0.1           19.0  \n","1196745            0.7           19.0  \n","1196746            0.3           20.0  \n","\n","[1196747 rows x 87 columns]"],"text/html":["\n","  <div id=\"df-526ffdf4-60e1-441b-9bf0-fb69373bf0c0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name_file</th>\n","      <th>time_stamp</th>\n","      <th>asset_id</th>\n","      <th>id</th>\n","      <th>train_test</th>\n","      <th>status_type_id</th>\n","      <th>sensor_0_avg</th>\n","      <th>sensor_1_avg</th>\n","      <th>sensor_2_avg</th>\n","      <th>wind_speed_3_avg</th>\n","      <th>...</th>\n","      <th>sensor_47</th>\n","      <th>sensor_48</th>\n","      <th>sensor_49</th>\n","      <th>sensor_50</th>\n","      <th>sensor_51</th>\n","      <th>sensor_52_avg</th>\n","      <th>sensor_52_max</th>\n","      <th>sensor_52_min</th>\n","      <th>sensor_52_std</th>\n","      <th>sensor_53_avg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.csv</td>\n","      <td>03/08/2022 06:10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>train</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>302.9</td>\n","      <td>129.4</td>\n","      <td>1.7</td>\n","      <td>...</td>\n","      <td>-496.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1280.0</td>\n","      <td>-496.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.csv</td>\n","      <td>03/08/2022 06:20</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>train</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>307.1</td>\n","      <td>133.6</td>\n","      <td>1.7</td>\n","      <td>...</td>\n","      <td>-490.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1278.0</td>\n","      <td>-490.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.csv</td>\n","      <td>03/08/2022 06:30</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>train</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>340.6</td>\n","      <td>167.1</td>\n","      <td>0.9</td>\n","      <td>...</td>\n","      <td>-490.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1356.0</td>\n","      <td>-490.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.csv</td>\n","      <td>03/08/2022 06:40</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>train</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>124.4</td>\n","      <td>-49.1</td>\n","      <td>1.5</td>\n","      <td>...</td>\n","      <td>-509.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1274.0</td>\n","      <td>-509.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.csv</td>\n","      <td>03/08/2022 06:50</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>train</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>66.2</td>\n","      <td>-107.3</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>-499.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1284.0</td>\n","      <td>-499.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1196742</th>\n","      <td>92.csv</td>\n","      <td>2023-04-16 09:20:00</td>\n","      <td>11</td>\n","      <td>54062</td>\n","      <td>prediction</td>\n","      <td>5</td>\n","      <td>15.0</td>\n","      <td>117.8</td>\n","      <td>4.8</td>\n","      <td>2.7</td>\n","      <td>...</td>\n","      <td>-328.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-772.0</td>\n","      <td>-328.0</td>\n","      <td>1.4</td>\n","      <td>2.7</td>\n","      <td>0.0</td>\n","      <td>1.1</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>1196743</th>\n","      <td>92.csv</td>\n","      <td>2023-04-16 09:30:00</td>\n","      <td>11</td>\n","      <td>54063</td>\n","      <td>prediction</td>\n","      <td>5</td>\n","      <td>16.0</td>\n","      <td>69.7</td>\n","      <td>-32.0</td>\n","      <td>2.3</td>\n","      <td>...</td>\n","      <td>-231.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-725.0</td>\n","      <td>-231.0</td>\n","      <td>0.3</td>\n","      <td>2.1</td>\n","      <td>0.0</td>\n","      <td>0.7</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>1196744</th>\n","      <td>92.csv</td>\n","      <td>2023-04-16 09:40:00</td>\n","      <td>11</td>\n","      <td>54064</td>\n","      <td>prediction</td>\n","      <td>5</td>\n","      <td>16.0</td>\n","      <td>69.8</td>\n","      <td>-16.9</td>\n","      <td>2.8</td>\n","      <td>...</td>\n","      <td>-492.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-844.0</td>\n","      <td>-492.0</td>\n","      <td>1.9</td>\n","      <td>2.1</td>\n","      <td>1.6</td>\n","      <td>0.1</td>\n","      <td>19.0</td>\n","    </tr>\n","    <tr>\n","      <th>1196745</th>\n","      <td>92.csv</td>\n","      <td>2023-04-16 09:50:00</td>\n","      <td>11</td>\n","      <td>54065</td>\n","      <td>prediction</td>\n","      <td>5</td>\n","      <td>16.0</td>\n","      <td>63.5</td>\n","      <td>-10.6</td>\n","      <td>2.4</td>\n","      <td>...</td>\n","      <td>-228.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-731.0</td>\n","      <td>-228.0</td>\n","      <td>0.4</td>\n","      <td>1.8</td>\n","      <td>0.0</td>\n","      <td>0.7</td>\n","      <td>19.0</td>\n","    </tr>\n","    <tr>\n","      <th>1196746</th>\n","      <td>92.csv</td>\n","      <td>2023-04-16 10:00:00</td>\n","      <td>11</td>\n","      <td>54066</td>\n","      <td>prediction</td>\n","      <td>5</td>\n","      <td>16.0</td>\n","      <td>91.9</td>\n","      <td>17.8</td>\n","      <td>3.1</td>\n","      <td>...</td>\n","      <td>-544.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-858.0</td>\n","      <td>-544.0</td>\n","      <td>1.9</td>\n","      <td>2.2</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>20.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1196747 rows × 87 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-526ffdf4-60e1-441b-9bf0-fb69373bf0c0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-526ffdf4-60e1-441b-9bf0-fb69373bf0c0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-526ffdf4-60e1-441b-9bf0-fb69373bf0c0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5d7e9583-b869-4e0e-8a92-d92e5794df71\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d7e9583-b869-4e0e-8a92-d92e5794df71')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5d7e9583-b869-4e0e-8a92-d92e5794df71 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_12b8e89e-2b50-4558-828e-8ff5bc50e3d4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_12b8e89e-2b50-4558-828e-8ff5bc50e3d4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# how many values  in colunm asset_id ?\n","df['status_type_id'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"wgyVM4bYb6Wp","executionInfo":{"status":"ok","timestamp":1741695877334,"user_tz":-60,"elapsed":14,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}},"outputId":"3dbeb3f6-0cf3-448f-9989-7bbe24d1b53f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["status_type_id\n","0    898672\n","5    260387\n","3     23689\n","4     13999\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>status_type_id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>898672</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>260387</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23689</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13999</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#je veux créer une variable STATUS_ID qui vaut \"normal\" si la valeur de status_type_id vaut 0 ou 2 et \"not normal\" sinon\n","df['status_id'] = np.where(df['status_type_id'].isin([0, 2]), 'normal', 'not normal')"],"metadata":{"id":"vnrwEEiS60by","executionInfo":{"status":"ok","timestamp":1741695927068,"user_tz":-60,"elapsed":275,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df['status_id'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"cf_I8Jhb7KQz","executionInfo":{"status":"ok","timestamp":1741695927269,"user_tz":-60,"elapsed":126,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}},"outputId":"fca6867e-46b2-4c05-f8ed-d8a35a1a5781"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["status_id\n","normal        898672\n","not normal    298075\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>status_id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>normal</th>\n","      <td>898672</td>\n","    </tr>\n","    <tr>\n","      <th>not normal</th>\n","      <td>298075</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["sensor_columns = [col for col in df.columns if any(x in col for x in\n","                        ['sensor', 'wind_speed', 'power'])]\n","len(sensor_columns)"],"metadata":{"id":"H9-IzRyRdkd9","executionInfo":{"status":"aborted","timestamp":1741696580306,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configuration de l'affichage\n","plt.style.use('seaborn-v0_8-whitegrid')\n","sns.set_palette(\"deep\")\n","plt.rcParams['figure.figsize'] = (12, 6)\n","plt.rcParams['font.size'] = 12"],"metadata":{"id":"N08ooIkEccX7","executionInfo":{"status":"ok","timestamp":1741695933519,"user_tz":-60,"elapsed":18,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class Autoencoder(nn.Module):\n","    def __init__(self, input_dim, encoding_dim=16):\n","        \"\"\"\n","        Architecture de l'autoencoder pour la détection d'anomalies\n","\n","        Args:\n","            input_dim: Dimension des données d'entrée (nombre de capteurs)\n","            encoding_dim: Dimension de la couche latente (compressée)\n","        \"\"\"\n","        super(Autoencoder, self).__init__()\n","\n","        # Encodeur - compresse les données d'entrée\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),  # Prévention du surapprentissage\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, encoding_dim),\n","            nn.ReLU()\n","        )\n","\n","        # Décodeur - reconstruit les données à partir de la représentation compressée\n","        self.decoder = nn.Sequential(\n","            nn.Linear(encoding_dim, 32),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(32, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, input_dim),\n","            nn.Sigmoid()  # Normalise les sorties entre 0 et 1\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"Propagation avant: encode puis décode les données\"\"\"\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n"],"metadata":{"id":"tbTBTGkScX1e","executionInfo":{"status":"ok","timestamp":1741695936399,"user_tz":-60,"elapsed":53,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Autoencoder(nn.Module):\n","    def __init__(self, input_dim, encoding_dim=16):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 128),  # Augmentation du nombre de neurones\n","            nn.LeakyReLU(),  # Utilisation de LeakyReLU\n","            nn.Dropout(0.3),  # Ajustement du taux de Dropout\n","            nn.Linear(128, 64),\n","            nn.LeakyReLU(),\n","            nn.Linear(64, encoding_dim),\n","            nn.LeakyReLU()\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(encoding_dim, 64),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, 128),\n","            nn.LeakyReLU(),\n","            nn.Linear(128, input_dim),\n","            nn.Sigmoid()  # Vous pouvez changer cela si nécessaire\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded"],"metadata":{"id":"1Kc0g0Pmw1up","executionInfo":{"status":"ok","timestamp":1741691994870,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["class WindTurbineAnomalyDetector:\n","    def __init__(self, encoding_dim=16):\n","        \"\"\"\n","        Détecteur d'anomalies pour les données d'éoliennes\n","\n","        Args:\n","            encoding_dim: Dimension de la couche latente de l'autoencoder\n","        \"\"\"\n","        self.encoding_dim = encoding_dim\n","        self.scaler = StandardScaler()  # Pour normaliser les données\n","        self.model = None\n","        self.threshold = None\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        print(f\"Utilisation de: {self.device}\")\n","\n","    def preprocess_data(self, df):\n","        \"\"\"\n","        Prétraitement des données: sélection et normalisation des capteurs\n","\n","        Args:\n","            df: DataFrame contenant les données des capteurs\n","\n","        Returns:\n","            X_scaled: Données normalisées\n","            sensor_columns: Noms des colonnes sélectionnées\n","        \"\"\"\n","        # Sélection des colonnes pertinentes (capteurs uniquement)\n","        sensor_columns = [col for col in df.columns if any(x in col for x in\n","                        ['sensor', 'wind_speed', 'power'])]\n","\n","        print(f\"Nombre de capteurs sélectionnés: {len(sensor_columns)}\")\n","\n","        # Vérification et nettoyage des données\n","        X = df[sensor_columns].copy()\n","\n","        # Remplacer les valeurs infinies par NaN\n","        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","\n","        # Vérifier s'il y a des valeurs NaN et les remplacer par la moyenne de la colonne\n","        if X.isna().any().any():\n","            print(f\"Attention: {X.isna().sum().sum()} valeurs NaN détectées et remplacées\")\n","            X.fillna(X.mean(), inplace=True)\n","\n","        # Normalisation des caractéristiques\n","        X_scaled = self.scaler.fit_transform(X)\n","\n","        return X_scaled, sensor_columns\n","\n","    def train(self, df, epochs=50, batch_size=64, learning_rate=0.0001,checkpoint_dir='checkpoints'):\n","        \"\"\"\n","        Entraînement de l'autoencoder\n","\n","        Args:\n","            df: DataFrame contenant les données d'entraînement\n","            epochs: Nombre d'époques d'entraînement\n","            batch_size: Taille des lots pour l'entraînement\n","            learning_rate: Taux d'apprentissage\n","\n","        Returns:\n","            losses: Liste des pertes d'entraînement\n","        \"\"\"\n","        # Prétraitement des données\n","        X, sensor_columns = self.preprocess_data(df)\n","\n","        # Conversion en tenseurs PyTorch\n","        X_tensor = torch.FloatTensor(X).to(self.device)\n","        dataset = TensorDataset(X_tensor, X_tensor)  # Les entrées = sorties attendues\n","        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","        # Construction du modèle\n","        if self.model is None:\n","            self.model = Autoencoder(X.shape[1], self.encoding_dim).to(self.device)\n","            print(f\"Modèle créé avec {X.shape[1]} entrées et dimension latente de {self.encoding_dim}\")\n","\n","        # Fonction de perte et optimiseur\n","        criterion = nn.MSELoss()  # Erreur quadratique moyenne\n","        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)  # Ajout de régularisation L2\n","\n","        # Créer le répertoire de checkpoints s'il n'existe pas\n","        Path(checkpoint_dir).mkdir(exist_ok=True)\n","\n","        start_epoch = 0\n","        # Charger le dernier checkpoint s'il existe\n","        checkpoints = list(Path(checkpoint_dir).glob('epoch_*.pth'))\n","        if checkpoints:\n","            latest_checkpoint = max(checkpoints, key=lambda p: int(p.stem.split('_')[1]))\n","            checkpoint = torch.load(latest_checkpoint)\n","            start_epoch = checkpoint['epoch']\n","            self.model.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            print(f\"Reprise de l'entraînement à partir de l'epoch {start_epoch}\")\n","\n","        # Boucle d'entraînement\n","        losses = []\n","        self.model.train()  # Mode entraînement\n","        # Boucle d'entraînement\n","        losses = []\n","        self.model.train()  # Mode entraînement\n","\n","        print(\"Début de l'entraînement...\")\n","        for epoch in range(start_epoch,epochs):\n","\n","            epoch_loss = 0\n","            for data, _ in dataloader:\n","                # Propagation avant\n","                outputs = self.model(data)\n","                loss = criterion(outputs, data)\n","\n","                # Vérification de la perte\n","                if torch.isnan(loss):\n","                    print(f\"Alerte: Perte NaN détectée à l'époque {epoch+1}. Arrêt de l'entraînement.\")\n","                    return losses\n","\n","                # Rétropropagation\n","                optimizer.zero_grad()  # Réinitialisation des gradients\n","                loss.backward()        # Calcul des gradients\n","\n","                # Clip des gradients pour éviter l'explosion\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","                optimizer.step()       # Mise à jour des poids\n","\n","                epoch_loss += loss.item()\n","\n","            # Calcul de la perte moyenne pour cette époque\n","            avg_loss = epoch_loss / len(dataloader)\n","            losses.append(avg_loss)\n","\n","            print(f'Époque [{epoch+1}/{epochs}], Perte: {avg_loss:.6f}')\n","            # Enregistrer le checkpoint\n","            checkpoint_path = Path(checkpoint_dir) / f'epoch_{epoch + 1}.pth'\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': self.model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': avg_loss,\n","            }, checkpoint_path)\n","\n","        print(\"Entraînement terminé!\")\n","\n","        # Calcul du seuil d'erreur de reconstruction\n","        self.model.eval()  # Mode évaluation\n","        with torch.no_grad():\n","            reconstructions = self.model(X_tensor).cpu().numpy()\n","\n","        # Calcul de l'erreur quadratique moyenne pour chaque exemple\n","        mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n","\n","        # Définition du seuil comme le 95ème percentile des erreurs\n","        self.threshold = np.percentile(mse, 95)\n","        print(f\"Seuil d'anomalie calculé: {self.threshold:.6f}\")\n","\n","        return losses\n","\n","    def detect_anomalies(self, df):\n","        \"\"\"\n","        Détection des anomalies dans les données\n","\n","        Args:\n","            df: DataFrame contenant les données à analyser\n","\n","        Returns:\n","            results: DataFrame avec les erreurs de reconstruction et les anomalies\n","        \"\"\"\n","        # Prétraitement des données\n","        X, _ = self.preprocess_data(df)\n","\n","        # Conversion en tenseurs PyTorch\n","        X_tensor = torch.FloatTensor(X).to(self.device)\n","\n","        # Obtention des reconstructions\n","        self.model.eval()\n","        with torch.no_grad():\n","            reconstructions = self.model(X_tensor).cpu().numpy()\n","\n","        # Calcul de l'erreur MSE\n","        mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n","\n","        # Détection des anomalies (erreur > seuil)\n","        anomalies = mse > self.threshold\n","\n","        # Création d'un DataFrame avec les résultats\n","        results = pd.DataFrame({\n","            'reconstruction_error': mse,\n","            'anomaly': anomalies\n","        }, index=df.index)\n","\n","        return results\n","\n","    def plot_history(self, losses):\n","        \"\"\"Visualisation de l'historique d'entraînement\"\"\"\n","        plt.figure(figsize=(12, 4))\n","        plt.plot(losses)\n","        plt.title('Évolution de la perte pendant l\\'entraînement')\n","        plt.xlabel('Époque')\n","        plt.ylabel('Perte (MSE)')\n","        plt.grid(True)\n","        plt.show()\n","\n","    def plot_anomalies(self, df, results):\n","        \"\"\"Visualisation des anomalies détectées\"\"\"\n","        plt.figure(figsize=(15, 7))\n","\n","        # Tri par timestamp\n","        df_sorted = df.sort_values('time_stamp')\n","        results_sorted = results.loc[df_sorted.index]\n","\n","        # Tracé de l'erreur de reconstruction\n","        plt.scatter(df_sorted['time_stamp'], results_sorted['reconstruction_error'],\n","                   c=results_sorted['anomaly'], cmap='coolwarm', alpha=0.7)\n","\n","        plt.axhline(y=self.threshold, color='r', linestyle='--', label=f'Seuil ({self.threshold:.4f})')\n","        plt.title('Détection d\\'anomalies dans les données d\\'éoliennes')\n","        plt.xlabel('Date')\n","        plt.ylabel('Erreur de reconstruction')\n","        plt.colorbar(label='Anomalie')\n","        plt.legend()\n","        plt.xticks(rotation=45)\n","        plt.tight_layout()\n","        plt.show()\n","\n","        # Distribution des erreurs de reconstruction\n","        plt.figure(figsize=(12, 5))\n","        plt.subplot(1, 2, 1)\n","        sns.histplot(results['reconstruction_error'], bins=50, kde=True)\n","        plt.axvline(x=self.threshold, color='r', linestyle='--', label=f'Seuil ({self.threshold:.4f})')\n","        plt.title('Distribution des erreurs de reconstruction')\n","        plt.xlabel('Erreur de reconstruction')\n","        plt.ylabel('Fréquence')\n","        plt.legend()\n","\n","        plt.subplot(1, 2, 2)\n","        sns.boxplot(x=results['anomaly'], y=results['reconstruction_error'])\n","        plt.title('Erreurs de reconstruction par classe')\n","        plt.xlabel('Anomalie')\n","        plt.ylabel('Erreur de reconstruction')\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"1zF4oUkecuBJ","executionInfo":{"status":"ok","timestamp":1741695941565,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def analyze_sensor_contribution(detector, test_data, anomaly_results):\n","    \"\"\"Analyse la contribution de chaque capteur aux anomalies détectées\"\"\"\n","    # Prétraitement des données\n","    X, sensor_columns = detector.preprocess_data(test_data)\n","\n","    # Conversion en tenseurs PyTorch\n","    X_tensor = torch.FloatTensor(X).to(detector.device)\n","\n","    # Obtention des reconstructions\n","    detector.model.eval()\n","    with torch.no_grad():\n","        reconstructions = detector.model(X_tensor).cpu().numpy()\n","\n","    # Calcul de l'erreur par capteur\n","    sensor_errors = np.power(X - reconstructions, 2)\n","\n","    # Création d'un DataFrame avec les erreurs par capteur\n","    sensor_error_df = pd.DataFrame(sensor_errors, columns=sensor_columns)\n","\n","    # Ajout de l'information d'anomalie\n","    sensor_error_df['anomaly'] = anomaly_results['anomaly'].values\n","\n","    # Calcul de l'erreur moyenne par capteur pour les anomalies vs non-anomalies\n","    anomaly_errors = sensor_error_df[sensor_error_df['anomaly']].mean()\n","    normal_errors = sensor_error_df[~sensor_error_df['anomaly']].mean()\n","\n","    # Calcul du ratio d'erreur (anomalie / normal)\n","    error_ratio = anomaly_errors / normal_errors\n","    error_ratio = error_ratio.drop('anomaly')\n","\n","    # Tri des capteurs par ratio d'erreur\n","    top_sensors = error_ratio.sort_values(ascending=False)\n","\n","    return top_sensors, sensor_error_df\n"],"metadata":{"id":"rEvnrIbOc0BK","executionInfo":{"status":"ok","timestamp":1741695942005,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def run_analysis():\n","    # Chargement des données\n","    #data_path = Path(r'/content/drive/MyDrive/GDM5 project/combined_data.parquet')\n","    #df = pd.read_parquet(data_path)\n","\n","    # Conversion du timestamp en format datetime\n","    df['time_stamp'] = pd.to_datetime(df['time_stamp'], format='mixed')\n","\n","    # Séparation des données d'entraînement et de test\n","    train_data = df[(df['train_test'] == 'train') & (df['status_id'] == 'normal')] # Nouvelle ligne\n","    test_data = df[df['train_test'] == 'prediction']\n","\n","    print(f\"\\nDonnées d'entraînement: {len(train_data)} lignes\")\n","    print(f\"Données de test: {len(test_data)} lignes\")\n","\n","    # Création et entraînement du détecteur\n","    detector = WindTurbineAnomalyDetector(encoding_dim=16)\n","    losses = detector.train(train_data, epochs=20, checkpoint_dir='analysis_checkpoints')\n","    # Visualisation de l'entraînement\n","    detector.plot_history(losses)\n","\n","    # Détection des anomalies\n","    print(\"Détection des anomalies sur les données de test...\")\n","    anomaly_results = detector.detect_anomalies(test_data)\n","\n","    # Statistiques des anomalies\n","    anomaly_count = anomaly_results['anomaly'].sum()\n","    print(f\"Nombre d'anomalies détectées: {anomaly_count}\")\n","    print(f\"Pourcentage d'anomalies: {(anomaly_count / len(test_data)) * 100:.2f}%\")\n","\n","    # Visualisation des anomalies\n","    detector.plot_anomalies(test_data, anomaly_results)\n","\n","    # Analyse des capteurs les plus influents\n","    top_sensors, sensor_error_df = analyze_sensor_contribution(detector, test_data, anomaly_results)\n","\n","    # Visualisation des capteurs les plus influents\n","    plt.figure(figsize=(14, 6))\n","    top_sensors.head(15).plot(kind='bar')\n","    plt.title('Top 15 des capteurs contribuant le plus aux anomalies')\n","    plt.xlabel('Capteur')\n","    plt.ylabel('Ratio d\\'erreur (Anomalie/Normal)')\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Sauvegarde du modèle\n","    model_path = Path(r'c:\\Users\\moham\\Desktop\\GDM5 project\\models')\n","    model_path.mkdir(exist_ok=True)\n","    torch.save(detector.model.state_dict(), model_path / 'autoencoder_model.pth')\n","    joblib.dump(detector.scaler, model_path / 'scaler.pkl')\n","    joblib.dump(detector.threshold, model_path / 'threshold.pkl')\n","\n","    return detector, anomaly_results, top_sensors\n","\n","if __name__ == \"__main__\":\n","    # Exécuter l'analyse complète\n","    detector, anomaly_results, top_sensors = run_analysis()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"id":"nY5N6MP9c4wO","executionInfo":{"status":"error","timestamp":1741696580290,"user_tz":-60,"elapsed":637847,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}},"outputId":"839872be-0210-4911-a099-e1eb35b0f6e1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Données d'entraînement: 859574 lignes\n","Données de test: 50593 lignes\n","Utilisation de: cuda\n","Nombre de capteurs sélectionnés: 81\n","Attention: 10 valeurs NaN détectées et remplacées\n","Modèle créé avec 81 entrées et dimension latente de 16\n","Début de l'entraînement...\n","Époque [1/20], Perte: 0.671420\n","Époque [2/20], Perte: 0.632547\n","Époque [3/20], Perte: 0.624781\n","Époque [4/20], Perte: 0.621608\n","Époque [5/20], Perte: 0.619170\n","Époque [6/20], Perte: 0.617152\n","Époque [7/20], Perte: 0.615400\n","Époque [8/20], Perte: 0.612613\n","Époque [9/20], Perte: 0.611059\n","Époque [10/20], Perte: 0.610120\n","Époque [11/20], Perte: 0.609382\n","Époque [12/20], Perte: 0.608725\n","Époque [13/20], Perte: 0.608214\n","Époque [14/20], Perte: 0.607721\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-c136b3a2ab71>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Exécuter l'analyse complète\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_sensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-c136b3a2ab71>\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Création et entraînement du détecteur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindTurbineAnomalyDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'analysis_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Visualisation de l'entraînement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-12c510f30d32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, df, epochs, batch_size, learning_rate, checkpoint_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# Mise à jour des poids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;31m# bake-in time before making it the default, even if it is typically faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         _, foreach = _default_to_fused_or_foreach(\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_default_to_fused_or_foreach\u001b[0;34m(params, differentiable, use_fused)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0;31m     foreach = not fused and all(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         or (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0;31m     foreach = not fused and all(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         or (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","checkpoint_dir = 'analysis_checkpoints'  # Remplacez par le répertoire approprié\n","\n","for filename in os.listdir(checkpoint_dir):\n","    if filename.startswith('epoch_') and filename.endswith('.pth'):\n","        file_path = os.path.join(checkpoint_dir, filename)\n","        os.remove(file_path)\n","\n","# Ou, pour supprimer tout le contenu du répertoire :\n","# shutil.rmtree(checkpoint_dir)  # Attention, cela supprimera tout dans le répertoire !"],"metadata":{"id":"c1kSzm2i2kGG","executionInfo":{"status":"ok","timestamp":1741692094618,"user_tz":-60,"elapsed":15,"user":{"displayName":"Aaron Simon","userId":"00275679209075055609"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QCfV2aih8Ar_"},"execution_count":null,"outputs":[]}]}